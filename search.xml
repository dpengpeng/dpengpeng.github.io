<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>flink</title>
    <url>/2021/07/13/flink/</url>
    <content><![CDATA[<h2 id="flink"><a href="#flink" class="headerlink" title="flink"></a>flink</h2><ol>
<li><p>flink执行图：</p>
<ul>
<li>streamGraph–&gt;jobGraph–&gt;executionGraph</li>
</ul>
</li>
<li><p>flink的两种状态</p>
<ul>
<li>operator state</li>
<li>keyed state</li>
</ul>
</li>
<li><p>flink状态一致性级别</p>
<ul>
<li>精确一次</li>
<li>至少一次</li>
<li>做多一次<span id="more"></span></li>
</ul>
</li>
<li><p>几种状态后端</p>
<ul>
<li>MemoryStateBackend</li>
<li>FsStateBackend</li>
<li>RocksDBStateBackend</li>
</ul>
</li>
<li><p>flink的常用数据类型</p>
<ul>
<li>java的基础数据类型</li>
<li>tuple</li>
<li>pojo</li>
<li>ArrayList,HashMap</li>
</ul>
</li>
<li><p>flink中的时间类型</p>
<ul>
<li>event time</li>
<li>processing time</li>
<li>ingestion time</li>
</ul>
</li>
<li><p>flink on yarn</p>
<ul>
<li>两种模式：<ul>
<li>session模式: 所有任务共享一个flink 集群，任务与任务之间会有影响，不用</li>
<li>pre-job模式: 每个任务一个独立的flinK集群,但是jar包的解析，生成JobGraph都是在客户端，当用户多时，客户端压力大</li>
<li>application模式：每个任务一个独立的flinlk集群，</li>
</ul>
</li>
<li>Flink On Yarn依赖Yarn资源调度和管理，动态申请资源启动Flink Cluster。每个被Yarn调度运行的Flink Cluster即为一个Application。Application包含了完成的Flink角色JobManager（ApplicationMaster/Container）、TaskManager（Container) </li>
</ul>
</li>
</ol>
<h1 id="flink笔记"><a href="#flink笔记" class="headerlink" title="flink笔记"></a>flink笔记</h1><h2 id="1-checkpoint-–-gt-snapshot"><a href="#1-checkpoint-–-gt-snapshot" class="headerlink" title="1.checkpoint –&gt;snapshot"></a>1.checkpoint –&gt;snapshot</h2><p>周期性的自动做状态快照，记录任务所有节点再某一时刻的处理状态，便于任务异常重启时从异常时间点进行状态恢复，仿佛没有发生任何异常。<br>执行checkpinting时，会在流中插入一个barrier，相当于一个屏障，用来区分某一个节点的前与后；</p>
<h2 id="2-savepoint"><a href="#2-savepoint" class="headerlink" title="2.savepoint"></a>2.savepoint</h2><p>手动创建一个保存点，用于停止任务然后重启，从某一个指定的时间点进行重新运行</p>
<h2 id="3-event-time-and-watermark"><a href="#3-event-time-and-watermark" class="headerlink" title="3.event-time and watermark"></a>3.event-time and watermark</h2><p>event-time 描述真实的事件发生时间<br>使用event-time就需要提供timestamp提取器和watermark生成器<br>watermark的作用:This is precisely what watermarks do — they define when to stop waiting for earlier events.<br>带时间戳的事件流在不确定是否有序的情况下进行传输，使用watermark来衡量何时停止等待早期事件，在时间窗口中经常使用。</p>
<p>event-time处理依赖watermark生成器，根据timestamp生成一个watermark(特殊时间戳)，然后插入到事件流中。<br>假设一个watermark=t,则代表可以认为时间T&lt;=t的事件流都已经全部到达了。当后期一个T &lt; t 的事件流再次出现时，可以认为此事件流为迟到的事件。</p>
<p>对于迟到的事件，默认是删除。也可以通过side-output方式输出到其他流中进行针对处理。</p>
<h2 id="4-window-功能可以用keyedProcessFunction来间接实现"><a href="#4-window-功能可以用keyedProcessFunction来间接实现" class="headerlink" title="4.window 功能可以用keyedProcessFunction来间接实现"></a>4.window 功能可以用keyedProcessFunction来间接实现</h2><h2 id="5-exactly-once"><a href="#5-exactly-once" class="headerlink" title="5.exactly-once"></a>5.exactly-once</h2><p>任务异常时，消息的消费就会存在丢失或者重复。那么flink的消息处理会面临以下三种：</p>
<ol>
<li>Flink makes no effort to recover from failures (at most once)</li>
<li>Nothing is lost, but you may experience duplicated results (at least once)</li>
<li>Nothing is lost or duplicated (exactly once)</li>
</ol>
<p>at most once意味着没有开启checkpointing功能;<br>exactly-once的开启意味着barrier对齐功能开启；<br>at least once的开启意味着barrier对齐功能没有开启；</p>
<p>barrier对齐指的是，一个operator假设接收两个以上的输入流，当发生一次checkpoint时，每个输入流都会插入一个barrier，并且这些barrier都会流到这个operator上，如果开始对齐功能，则这个operator上的checkpoint会等待所有的barrier收集齐了才能继续进行后续数据的传输，先到的barrier需要等待后到的barrier并且缓存自己数据线源源不断的流数据；如果不开启对齐功能，则每个数据流自己barrier处理完后，operator会继续处理它后面的新数据，不需要关注其他输入流是否完成了barrier,此时当发生故障重启时，某些先checkpoint的数据流的数据就会被重新消费，因为一次完整的state需要所有的operator都完成checkpoint；</p>
<h2 id="6-Exactly-Once-End-to-end"><a href="#6-Exactly-Once-End-to-end" class="headerlink" title="6.Exactly Once End-to-end"></a>6.Exactly Once End-to-end</h2><p>端到端的一致性提供更好到的<br>To achieve exactly once end-to-end, so that every event from the sources affects the sinks exactly once, the following must be true:</p>
<ol>
<li>your sources must be replayable, and</li>
<li>your sinks must be transactional (or idempotent)</li>
</ol>
<h2 id="7-keyed-stream-amp-keyed-state"><a href="#7-keyed-stream-amp-keyed-state" class="headerlink" title="7.keyed stream &amp; keyed state"></a>7.keyed stream &amp; keyed state</h2><p>通过keyBy处理后的流，假设下游需要保存一个keyed state，那个每个key都会有相应的逻辑分区，实际上每个key的数据都是独立的，并不会多个key的state保存在同一个state中，不会常规的都放在同一个map的结构，key/value中的state value会被严格的绑定到event’s key。</p>
<h2 id="8-checkpoint-event-time-watermark-exactly-once关系"><a href="#8-checkpoint-event-time-watermark-exactly-once关系" class="headerlink" title="8.checkpoint,event time,watermark,exactly-once关系"></a>8.checkpoint,event time,watermark,exactly-once关系</h2><ol>
<li>checkpoint是用来给数据流进行状态快照的，有没有开启checkpoint意味着任务重启时是否能保留之前的处理状态，这是一个单独的参数</li>
<li>event-time与watermark必须绑定，这个是用来定义消息的实际时间和判断是否继续等待早期事件的依据时间点,这两个参数与checkpoint是否开启是无关的。</li>
<li>exactly-once语句和checkpoint绑定的，依赖状态快照，但是与watermark是无关的；</li>
</ol>
<h2 id="9-table-api-and-sql-api"><a href="#9-table-api-and-sql-api" class="headerlink" title="9.table api and sql api"></a>9.table api and sql api</h2><p>flink的流批一体是通过table 和sql功能实现的，目前table planner推荐使用Blink planner;<br>flink sql的环境设置分三步：<br>EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();<br>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>StreamTableEnvironment tEnv = StreamTableEnvironment.create(env, settings);</p>
<p>flink sql里面的execute()方法不用显示调用了。</p>
<h2 id="10-flink-sql-控制并发度"><a href="#10-flink-sql-控制并发度" class="headerlink" title="10 flink sql 控制并发度"></a>10 flink sql 控制并发度</h2><h2 id="11-flink-keyby"><a href="#11-flink-keyby" class="headerlink" title="11.flink keyby"></a>11.flink keyby</h2><p>被keyby分流的后的数据会进入一个逻辑分区，可以理解为同样的一个key会被路由到同样的分区，但是一个分区可以接受不同的key划分过来的数据流，flink是通过散列的方式进行逻辑划分的，所以在keyby后面的计算单元中，需要注意一点，如果创建个容器进行装数据，那么如果是非state方式比如使用常规的hashmap进行存放数据，<br>那么这个hashmap实例数和并发数相等，同一个hashmap实例会被分配给hash(key)相同的不同key共享使用。而如果使用状态进行存储例如mapstate，那么因为state是根据key进行唯一绑定的，<br>所以不同的key就会有自己唯一对应的state进行存储数据。</p>
<h2 id="12-flink-taskmanager-内存"><a href="#12-flink-taskmanager-内存" class="headerlink" title="12.flink taskmanager 内存"></a>12.flink taskmanager 内存</h2><ul>
<li>从1.10后，flink对内存分配进行了升级。其中需要注意managed memory的使用；</li>
<li>managed memory 分配在堆外非直接内存中，其作用是：Batch jobs用来排序、存放HashTable、中间结果的缓存；Streaming jobs的RocksDB State Backend Memory。因此在streaming jobs中并且没有使用rocksdb statebackend时，这个值应该调整的比较小，可以为0，苏宁调整为flink memory的0.04，flink默认为0.4。</li>
</ul>
<h2 id="13-flink-taskmanager-slot-cpu-memory"><a href="#13-flink-taskmanager-slot-cpu-memory" class="headerlink" title="13.flink taskmanager slot cpu memory"></a>13.flink taskmanager slot cpu memory</h2><ul>
<li>flink任务都是运行在taskmanager中，jobmanager主要负责任务的调度等，taskmanager 的内存可以人为的自定义大小。</li>
<li>taskmanager中的slot默认为1个，可以设置多个，taskmanager中的cpu个数默认和slot是1:1比例的，每个slot会的内存是根据taskmanager进行平均分配的，内存资源是隔离的，但是cpu不是。</li>
<li>每个taskmanager只有一个jvm进行，slot相当于线程，多个slot是复用一个jvm的连接等资源。</li>
<li>实际实践中，根据taskmanager的大小，可以自行决定采用一个slot还是多个slot的方式来部署计算单元。</li>
<li>flink的可以根据需要执行jar包是人为的设置一些参数的大小，例如manager memory通过-yD taskmanager.memory.managed.fraction=0.04进行设置，slot数量通过-ys 2 进行设置。</li>
</ul>
<h2 id="14-flink-中每个slot与线程的关系"><a href="#14-flink-中每个slot与线程的关系" class="headerlink" title="14.flink 中每个slot与线程的关系"></a>14.flink 中每个slot与线程的关系</h2>]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2021/06/26/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Clean-older-history"><a href="#Clean-older-history" class="headerlink" title="Clean older history"></a>Clean older history</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo clean</span><br></pre></td></tr></table></figure>

<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server or hexo s</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate or hexo g</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy or hexo d</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
<h3 id="添加分类和标签"><a href="#添加分类和标签" class="headerlink" title="添加分类和标签"></a>添加分类和标签</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">categories: 分类名</span><br><span class="line">tags:</span><br><span class="line">- tag1</span><br><span class="line">- tag2</span><br></pre></td></tr></table></figure>
<h3 id="部署打包方式"><a href="#部署打包方式" class="headerlink" title="部署打包方式"></a>部署打包方式</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>
<h3 id="博客的同步与发布"><a href="#博客的同步与发布" class="headerlink" title="博客的同步与发布"></a>博客的同步与发布</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">github分支存在两个：</span><br><span class="line">* 默认分支为hexo,用于使用git管理内容</span><br><span class="line">* main分支为发布分支</span><br></pre></td></tr></table></figure>

<h3 id="分割符"><a href="#分割符" class="headerlink" title="分割符"></a>分割符</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- more --&gt;</span></span><br><span class="line">用于文章内容分割，more下面的内容默认不显示，通过点击阅读全文显示</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>java</title>
    <url>/2021/07/13/java/</url>
    <content><![CDATA[<h2 id="java-并发"><a href="#java-并发" class="headerlink" title="java 并发"></a>java 并发</h2><ol>
<li>cpu,内存，磁盘 之间的效率问题衍生出并发问题：可见性 原子性 有序性</li>
<li>解决并发: 就是解决上述衍生出来的三个问题<ul>
<li>volatile: 解决可见性和有序性问题，可见性就涉及到java的内存模型：主内存和每个线程自己的工作内存。每个线程访问的变量都是从主内存拿取，然后放在线程自己的工作内存(比如cpu寄存器)中使用的，更新完变量值后，可以再写回主内存。被volatile修饰的变量，每次读都是从主内存读取最新，更新完后立即再写回主内存，并且修饰后变量的位置顺序不会被编译器给指令优化。</li>
<li>锁：<ul>
<li>可以解决原子性问题。根据锁对并发性能的影响，产生了各种锁，synchronized,reentrantlock(可以配合condition使用,配合多个条件变量使用，然后可以通过wait将不同的线程放到不同的条件队列中等待唤醒,即等待通知机制)，readwritelock(内部分为读锁和写锁,读读ok,读写阻塞，写写阻塞，应用于读多写少)</li>
<li>synchronized锁可重入，不可中断，非公平锁</li>
<li>Lock的实现类锁可重入，可中断，也可以设置公平锁或者非公平锁,默认非公平锁</li>
</ul>
</li>
<li>无锁方式解决并发安全问题：<ul>
<li>final 修饰变量</li>
<li>使用ThreadLocal不共享变量</li>
<li>原子类中使用CAS(compare and swap比较并交换，内部用到了自旋)<span id="more"></span>
<h2 id="java-容器"><a href="#java-容器" class="headerlink" title="java 容器"></a>java 容器</h2></li>
</ul>
</li>
</ul>
</li>
<li>list:非线程安全(ArrayList LinkedList),线程安全(Vectory,使用Colletcions.synchronizedList(new ArrayList&lt;&gt;()),CopyOnWriteArrayList)<ul>
<li>CopyOnWriteArrayList: 是一种Copy-On-Write(COW)模式，即写时复制，适用于对读有高性能要求的场景，因为写时通过加锁会复制内部数组里面的元素，然后用新数字替换老数组，内部用了volatile。</li>
</ul>
</li>
<li>map: <ul>
<li>HashTable：<ul>
<li>内部数据结构：数组+链表</li>
<li>线程安全的，使用了synchronized，效率低</li>
<li>不能放null的key</li>
<li>初始容量为11</li>
</ul>
</li>
<li>HashMap :<ul>
<li>内部的数据结构时用数组+链表，根据hash值来定位在数组中的位置，同样的hash值再放入链表中，1.8用的尾插法，1.7用的头插法</li>
<li>初始长度为16，默认的加载因子为0.75(Constructs an empty HashMap with the default initial capacity  (16) and the default load factor (0.75));并且数组的容量扩充或者初始化时 必须时2的幂次方</li>
<li>从hash值映射到数组位置使用的时高效的位运算index=hashcode(key) &amp; (length-1);之所以数组的长度为16或者2的幂次方，是因为这种情况下leng-1的二进制所有位都是1(比如15是1111)，因此index的值就等同于hashcode的后几位值，只要key本身均匀，那么hash算法的结果就是均匀的。</li>
<li>hashmap是非同步的，因此并发情况下是非线程安全的：1.多线程同时插入数据时 2.resize时可能造成死循环</li>
<li>可以放null值的key和value</li>
<li>如果链表的长度超过阈值8，就会转换成红黑树(搜索性能高),如果链表长度小于6，就会把红黑树转回链表.红黑树是为了解决链表查询深度问题，单链表过长时查询性能低</li>
<li>如果容量满了(16*0.75),就会扩容2倍，然后重新插入数据</li>
<li>7和8里面的区别：8引入了红黑树，7没有；链表中插入新节点8时尾插法，7时头插法</li>
</ul>
</li>
<li>ConcurrentHashMap：<ul>
<li>基于hashmap,但是线程安全，性能比hashtable高 </li>
<li>7和8的区别:<ul>
<li>7中基于分段锁，先分成一个一个的segment，然后segment里面再放元素,锁会锁指定的segment，其他的segment可以正常读取 </li>
<li>8中抛弃了分段锁，采用cas+synchronize。如果元素第一次进入才用CAS方式插入，如果已经有链表了，则采用synchronized锁住表头进入插入.</li>
</ul>
</li>
</ul>
</li>
<li>TreeMap: 是对红黑树的一种实现，插入元素时可以对元素根据key进行排序。</li>
</ul>
</li>
</ol>
<h2 id="java-线程"><a href="#java-线程" class="headerlink" title="java 线程"></a>java 线程</h2><ol>
<li>通过Thread类初始化一个线程</li>
<li>通过直接实现runnable接口，再以参数形式传入到Thread中</li>
<li>可以通过callable+future/futertask配合，放入Thread中执行，可以获取线程执行的状态和结果</li>
<li>线程有sleep，wait方法，可以通过interrupt()方法终止线程，接收到终止信号的处于阻塞中的线程会发生InterruptedException,这些异常需要开发人员介入处理</li>
<li>异步编程：<ul>
<li>可以使用CompletableFuture进行线程之间的协调通信，分为异步和通过方式，链式调用协调执行。</li>
<li>可以使用countdownlatch进行多线程步调一致,latch对象会阻塞主线程等待子线程执行完。</li>
<li>可以使用CompletionService实现批量的执行异步任务,同时发起多个异步任务，然后哪个先到达就先得到哪个的执行结果。</li>
</ul>
</li>
<li>创建线程池的方式，不能使用newFixedThreadPool(int nThreads)，因为内部的任务队列时无界的，可能会产生oom，必须通过ThreadPoolExecutor自定义线程池，然后自己指定核心数，最大数，线程空闲时间，时间单位，放置任务的阻塞队列，创建线程工厂，拒绝任务策略.有界的阻塞队列ArrayBlockingQueue和LinkedBlockingQueue，必须指定队列大小；丢弃策略有4种:直接丢弃并抛异常，直接丢弃不抛异常，抛弃最老的任务，使用调用线程执行任务.</li>
</ol>
<h2 id="java中的动态代理"><a href="#java中的动态代理" class="headerlink" title="java中的动态代理"></a>java中的动态代理</h2><ol>
<li>静态代理:<ul>
<li>A接口，B实现A，人工再创建一个C实现A，将B注入C，然后通过调用C中的同名方法来实现额外的扩充功能</li>
<li>缺点就是，需要人工创建好每个需要的代理类</li>
</ul>
</li>
<li>动态代理：<ul>
<li>可以利用java反射机制，动态的生成一个代理类，不需要提前写好</li>
<li>java本身的动态代理是基于接口的动态代理(JDK代理)，而spring中的AOP引入了cglib代理(比如事务注解修饰的类或者方法)，可以实现不是接口也可以动态代理，是通过动态生成一个子类来实现代理类方法的,spring 会在需要的时候创建好动态类，插入特定的功能.</li>
<li>spring中动态代理的选择方式:<ul>
<li>如果目标对象实现了接口，则默认情况下采用jdk代理，也可以通过spring配置指定强制都采用cglib代理</li>
<li>如果目标对象没有实现接口，则采用cglib代理</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="jvm"><a href="#jvm" class="headerlink" title="jvm"></a>jvm</h2><ol>
<li>jvm内存模型:jdk1.8为标准<ul>
<li>内部结构分为两类：线程共享和线程私有</li>
<li>线程共享：堆和方法区(元空间)<ul>
<li>堆java heap：存放对象的，GC作用的地方，是jvm中占用内存最大的地方,里面</li>
<li>方法区(非堆Non-Heap)：存放类信息、常量、静态变量。1.8使用元空间来替代方法区,逻辑上也叫永久代</li>
</ul>
</li>
<li>线程私有：栈(jvm栈和本地方法栈)和程序计数器<ul>
<li>栈：分为jvm栈和本地方法栈，jvm用于执行java方法的，本地方法栈则用于执行native方法的</li>
<li>程序计数器：用于当前线程所执行的字节码的行号指示器.</li>
</ul>
</li>
<li>参考：<a href="https://www.nowcoder.com/discuss/151138?type=1">https://www.nowcoder.com/discuss/151138?type=1</a></li>
</ul>
</li>
<li>GC算法<ul>
<li>GC目前是采用分代回收算法，氛围新生代，老年代，永久代，不同代有具体的不同回收算法，新生代采用复制算法，老年代就需要采用标记清除算法</li>
<li>jvm提供的年轻代回收算法属于复制算法，CMS(8默认)、G1(9默认，8可用)，ZGC(11)属于标记清除算法。</li>
<li>垃圾收集器:<ul>
<li>CMS收集器，并发标记清理，先把所有活动的对象标记出来，然后把没有被标记的对象统一清除掉。但是它有两个问题，一是效率问题，两个过程的效率都不高。二是空间问题，清除之后会产生大量不连续的内存,产生空间碎片 </li>
<li>G1收集器优化了CMS，减少停顿，没有了物理上的年轻代，老年代，只有一些逻辑上的划分，使用一些非连续的区域来表示。</li>
</ul>
</li>
<li>参考：<a href="https://www.cnblogs.com/ityouknow/p/5614961.html">https://www.cnblogs.com/ityouknow/p/5614961.html</a></li>
<li>GC root：<ul>
<li>垃圾收集器是通过可达性分析算法来判断一个对象是否存活的，可达性分析就会以GC root对象为起点，一直往下寻找下一个节点，直到遍历完所有节点。如果相关对象不在任意一个以GC root的为起点的引用链，那么就判定这个对象为垃圾对象。</li>
<li>gc root有哪些：栈(jvm栈和本地方法栈)中的引用对象，方法区中的静态属性引用的对象(public static Test s)和方法区中常量的引用的对象(public static final Test s)</li>
</ul>
</li>
</ul>
</li>
<li>jvm参数和命令:<ul>
<li>参数:<ul>
<li>-Xmx：指定对最大值</li>
<li>-Xms：指定堆初始值,通常这两个值大小设置一样的</li>
<li>-XX:MetaspaceSize=1024m,设置元空间大小</li>
</ul>
</li>
<li>命令:<ul>
<li>jstack:显示java虚拟机当前的线程快照</li>
<li>jmap:显示java进程内存分配情况</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="http"><a href="#http" class="headerlink" title="http"></a>http</h2><ol>
<li>由于http是无状态的，因此如果服务端需要记住用户的状态，就需要通过session来识别用户即session id. session可以存放在内存，数据库，文件中都可。</li>
<li>跟踪session是通过cookie实现的，cookie中记录了session id，每次http发送请求时都会加上cookie信息给服务端，服务端存储了session文件，类似一个map，根据seesion id来寻找对应的会话.</li>
<li>http，session，cookie三种都是独立的东西，http是通过session和cookie来实现有状态的</li>
</ol>
<h2 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h2><ol>
<li>redis数据类型<ul>
<li>string：key-value格式，命令：set,get,del 举例：set age 23，set name “dpp”,get age,del name, 不存在的key返回nil</li>
<li>list: key-value格式，value为列表,命令：rpush mylist e1 将e1放到mylist列表的右端，lrange mylist 0 -1 ,0为起始未知，-1为结束未知，查询出所有的元素,lpop mylist 从mylist列表左边弹出一个元素</li>
<li>hash :key-value 格式,value内存也是key1-value1格式，hset myhash field1 value1,hmset myhash field1 value1 field2 value2 同时设置多个k-v，可以用于存对象类型数据</li>
<li>set:key-value格式,无序集合并且可以去重，内存存储的是string类型数据，sadd myset s1</li>
<li>zset:key-value格式,有序集合并且可以去重,每个元素有对应的分数</li>
</ul>
</li>
<li>redis分布式锁:<ul>
<li>setnx </li>
</ul>
</li>
<li>redis集群codis<ul>
<li>介绍：是redis的一个分布式方案,为了严格的数据一致性，slave是异步复制master，存在延迟和数据丢失风险，不支持读写分离；基于codis-proxy来访问server group,每个group 里面分为master和slave,分布式逻辑写在proxy，底层存储在redis，数据的分布状态存储在zk</li>
<li>现在生产集群节点是5*2的存储集群</li>
<li>codis通过presharding方式，先分出1024个slot，然后再将slot分配到多个redis组中，数据根据key计算到唯一的slot id，迁移数据也是将整个slot迁移走,hash算法是crc32(key)%1024</li>
<li>Redis的主从切换是通过codis-ha在zk上遍历各个server group的master判断存活情况，来决定是否发起提升新master的命令。</li>
<li>一致性hash算法：<ul>
<li>如果采用普通的hash函数时，当存储数据的节点数变动，比如扩容，那么就要重新分配数据分布，会导致大量的数据迁移，影响性能</li>
<li>一致性hash的原理是，首先虚拟一个hash环，范围是0-2^32-1(就是一个32位无符号整数范围)，先计算出机器节点对应的hash值，放入到环中对应的位置，然后再根据放入数据的key计算hash值，放入到hash环对应的位置，按照顺时针方向，数据遇到的第一个机器节点就是这个数据应该存放的节点。</li>
<li>根据一致性hash原理，加入扩容增加机器节点，那么只需要移动新增机器节点逆势针方向到上一个节点之间的数据即可。</li>
</ul>
</li>
</ul>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>kafka自问自答</title>
    <url>/2021/07/01/kafka%E8%87%AA%E9%97%AE%E8%87%AA%E7%AD%94/</url>
    <content><![CDATA[<h2 id="kafka是什么"><a href="#kafka是什么" class="headerlink" title="kafka是什么"></a>kafka是什么</h2><p>kafka是一开始是个消息中间件引擎，后来有了kafka streams后便可以提供流计算功能(以jar形式添加到一个应用中即可使用)</p>
<span id="more"></span>
<h2 id="kafka的consumer应知应会"><a href="#kafka的consumer应知应会" class="headerlink" title="kafka的consumer应知应会"></a>kafka的consumer应知应会</h2><ul>
<li>kafka的consumer分为standalone consumer 和 consumer group</li>
<li>standalone consumer 运行时只有一个消费者实例，单线程消费</li>
<li>consumer group 以组为单位进行消费topic,每个partition都会分配一个consumer，每个consumer可以有一个或者多个partition</li>
<li>kafka内部有个消费者位移主题__consumer_offset,默认50个partition，每个consumer group首先都会注册到50个partition中的某一个partition中，并且这个partition的leader所在的broker就是这个consumer group的协调者Coordinator,所有的consumer在加入组之前都要寻找到他所在组的Coordinator，然后等所有的consumer都加入组以后，Coordinator就会让leader consumer(第一个找到coordiantor的consumer)分配消费方案，然后coordinator就会将分配方案分发给各个consumer，这样整个consumer group就开始进行消费信息了</li>
<li>consumer group 会发生rebalance，此时整个consumer group就会停止消费，重新通过coordinator来分配新的消费方案才行</li>
<li>consumer group发生rebalance情景包括：新增consumer、consumer实例进程挂掉、consumer与coordinator的心跳响应超时、订阅的topic个数发生变化、topic的partitoin个数增加</li>
</ul>
<h2 id="kafka的producer应知应会"><a href="#kafka的producer应知应会" class="headerlink" title="kafka的producer应知应会"></a>kafka的producer应知应会</h2><ul>
<li>producer没有group的概念，每个producer 实例就一个独立的消费生产者</li>
<li>producer 0.11版本后提供了幂等性和事务性，为发送消息提供原子性保障，也即精确一次语义。幂等性只能保证单次会话单个分区的原子性，单次会话的某个分区不会出现重复消息，producer重启就不生效了。事务性则可以保证多个分区且重启之后仍然可以有原子性，事务性producer是read committed隔离级别的，所有的消息要么都成功，要么都失败。</li>
<li>producer 发送有个ack机制，发送后的消息符合ack规则才算成功提交，kafka只对已提交的消息提供一致性保障，并且根据ack的不同，保障性界别也不同。ack=all为最高级别，所有的partition副本都确认了才算提交成功。</li>
</ul>
<h2 id="kafka-broker应知应会"><a href="#kafka-broker应知应会" class="headerlink" title="kafka broker应知应会"></a>kafka broker应知应会</h2><ul>
<li>kafka broker 是通过zookeeper来进行分布式协调管理的，zookeeper中的watch机制可以让客户端是实时监控到znode节点的变化并作出相应的动作</li>
</ul>
<h2 id="topic-amp-amp-partition"><a href="#topic-amp-amp-partition" class="headerlink" title="topic &amp;&amp; partition"></a>topic &amp;&amp; partition</h2><ul>
<li>每个topic都会一个或者多个partition，每个partition都有一个或者多个副本</li>
<li>partition中分leader和follower角色，follower专门负责同步leader的消息，不读外提供读写服务</li>
<li>leader 会维护一个isr列表，里面放的是与leader同步的follwer，包括leader自己。虽然follwer不一定能实时与leader保持同步，不过只要符合一定规则就算同步(默认是follower延迟不超过leader 10s)</li>
<li>partition 里面有不同的游标：HW，LEO，offset。HW为高水位，为多个partition共识的可以被consumer消费的位移临界值(不包含hw处)，leo为一个partition最后一条消息的offset+1，代表放下一条消息的offset</li>
<li>当leader partition挂了以后，其他的follower就会竞选leader，当某个follower变成leader之后其他的follower就会来同步他的消息，如果某个follower的leo大于leader的leo，那么多余的消息就会被截断，因为这些消息不算已提交的，所以producer检测到上一次发送失败后就会重新发送消息，然后也会自动过滤掉重复的消息，进而将消息重新完整的发送到新的leader上面。</li>
</ul>
]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>springboot</title>
    <url>/2021/07/13/springboot/</url>
    <content><![CDATA[<ol>
<li>spring中不同的bean之间的依赖，是通过spring来进行依赖注入的，bean之间交给spring来管理.<br>spring可以在xml配置文件中，将bean的依赖关系给阐述出来，让spring读取xml来识别谁依赖谁。</li>
</ol>
<span id="more"></span>
<ol start="2">
<li><p>spring配置方式<br>a.基于xml的方式进行配置<br>在xml中描述bean之间的依赖关系</p>
<bean id="xxx" class="yyy">
<constructor-arg ref="zzz>
</bean>
b.基于java的配置
@Configuration
public class BbConfig {
 @Bean
 public Bb bb() {
     //依赖注入了aa这个bean
     // return new Bb(new Aa()); 这里bb中的Aa就变成了自己创建的对象了，而不是spring创建的
     return new Bb(aa());//这里aa()方法产生的就是spring给注入的bean
 }
 @Bean
 public Aa aa() {
     return new Aa();
 }
}</li>
<li><p>工作方式<br>spring通过应用上下文（Application Context）装载bean的定义并把它们组装起来。Spring应用上<br>下文全权负责对象的创建和组装。Spring自带了多种应用上下文的实现，它们之间主要的区别<br>仅仅在于如何加载配置。</p>
</li>
<li><p>aop<br>面向切面编程就是说，整个系统可以划分成各种不同功能的模块，每个模块负责自己的核心功能，<br>然后有些模块可以在不影响目标模块功能的前提下，作用到目标模块上，目标模块甚至都不知道自己被附加了这个模块，<br>这是一种无入侵式的功能绑定。<br>aop相对于调用一个抽象独立出来的方法而言，好处是对目标模块无注入影响，而公用方法，是需要嵌入到某个模块代码里面被调用的，<br>修改方法可能会影响目标模块。<br>aop的应用比如日志模块，事务模块，安全模块，可以用声明的方式作用到所要影响的组件上去。<br>aop的类是一个POJO类，是切面的同时前提也是一个spring bean，spring也可以像使用其他bean那样使用切面，比如依赖注入。</p>
</li>
</ol>
<p>AOP原理<br>如何把切面织入到核心逻辑中？这正是AOP需要解决的问题。换句话说，如何对调用方法进行拦截，并在拦截前后进行安全检查、日志、事务等处理，就相当于完成了所有业务功能。</p>
<p>在Java平台上，对于AOP的织入，有3种方式：</p>
<p>编译期：在编译时，由编译器把切面调用编译进字节码，这种方式需要定义新的关键字并扩展编译器，AspectJ就扩展了Java编译器，使用关键字aspect来实现织入；<br>类加载器：在目标类被装载到JVM时，通过一个特殊的类加载器，对目标类的字节码重新“增强”；<br>运行期：目标对象和切面都是普通Java类，通过JVM的动态代理功能或者第三方库实现运行期动态织入。</p>
<p>最简单的方式是第三种，Spring的AOP实现就是基于JVM的动态代理。由于JVM的动态代理要求必须实现接口，如果一个普通类没有业务接口，就需要通过CGLIB或者Javassist这些第三方库实现。<br>AOP技术看上去比较神秘，但实际上，它本质就是一个动态代理，让我们把一些常用功能如权限检查、日志、事务等，从每个业务方法中剥离出来。<br>需要特别指出的是，AOP对于解决特定问题，例如事务管理非常有用，这是因为分散在各处的事务代码几乎是完全相同的，并且它们需要的参数（JDBC的Connection）也是固定的。另一些特定问题，如日志，就不那么容易实现，因为日志虽然简单，但打印日志的时候，经常需要捕获局部变量，如果使用AOP实现日志，我们只能输出固定格式的日志，因此，使用AOP时，必须适合特定的场景。<br>spring调用动态代理的对象，其实已经不是原来自己的对象了，而是被spring包装过的对象，和单纯调用原始的对象不一样</p>
<p>spring 通过CGLIB来创建一个被aop作用的类的代理类，核心就是先初始化一个原始的类对象，然后通过继承这个类创建一个代理类，<br>等实际运行时，表面上代码层是调用原始类对象的方法，实际上，真实运行调用的是被代理类的同名方法.</p>
<ol start="5">
<li><p>spring使用模板来消除重复样式的代码<br>比如使用JdbcTemplate，来避免各种重复的jdbc操作，包括创建连接，捕获sqlexception，关闭连接等</p>
</li>
<li><p>spring容器大致可以分为两类：<br>a.基本bean 工厂的容器,最基础<br>b.基于应用上下文的容器，基于bean工厂，分了各种xxxApplicationContext 上下文，每种上下文负责初始化各自范围内的bean<br>spring容器负责bean的整个生命周期，从出生到死亡。</p>
</li>
</ol>
<ol start="7">
<li>spring对bean的操作有：自动扫描，自动装配，条件装配，占位符，spirng计算表达式，基于javaConfig，基于xml配置.</li>
</ol>
<ol start="8">
<li><p>@Autowired作用在普通方法上，会在注入的时候调用一次该方法，如果方法中有实体参数，会对方法里面的参数进行装配，并调用一次该方法。<br>这个可以用来在自动注入的时候做一些初始化操作。</p>
</li>
<li><p>aop失效场景(原始类servcie，aop代理后的类$service，代理类相当于是包裹在service外的子类，通过同名方法，内部实际再调用原始对象的方法):<br>a.在同一个类service中，一个无aop作用的普通方法func1里调用另一个有aop作用的方法func2，此时func2的aop方法会失效<br>解释：当调用func1时，因为此方法非并没有aop作用，因此用的就是原始service对象，内部方法也是通过this.func2调用的，因此整个过程用的都是原始对象sevice<br>b.在同一个类service中，一个有aop作用的方法func1调用另一个有aop作用的方法func2，此时func2的aop方法会失效<br>解释：当调用func1时，因为此方法有aop作用，spring会生成一个增强代理类$service，于是通过$service来调用func1，而func2的调用是通过this.func2，也就是没走代理类$service，因此this就是原始sevice，并不是代理类$service，于是aop的效果就失效了。</p>
</li>
</ol>
<p>解决方案:<br>a.将func1和func2放在两个不同的类中，然后需要依赖时，注入相关的依赖即可.<br>b.调用方法时，获取当前上下文的代理对象(通过AopContext.currentProxy())，然后通过代理对象进行方法调用,这种方案的前提是需要使用需要在AOP配置里暴露代理对象，在Spring Boot中可以通过注解@EnableAspectJAutoProxy(exposeProxy = true)进行配置。</p>
<ol start="10">
<li><p>spring boot<br>spring boot针对spring应用进行了变革，将各种繁琐的配置给简化，尽量的减少配置甚至无配置。<br>spring boot的自动配置特性，会探测pom.xml文件中的spirng-boot-starter-xxx.jar包，当加入相应的依赖时，就会自动配置出相应的bean出来使用，例如，加入spring-boot-starter-jdbc和com.h2database时，就会自动配置jdbcTemplate bean和 H2Database bean供使用.<br>@EnableAutoConfiguration启动自动配置.</p>
</li>
<li><p>spring boot项目内嵌tomcat和部署到独立的tomcat容器的启动类区别<br>a.当使用内嵌的tomcat时，不需要修改启动类，直接使用spring boot自动生成的启动类启动，此时包格式为jar包。<br>b.当使用独立的web容器运行项目时，例如jboss或者tomcat，则需要启动类继承SpringBootServletInitializer类，重写configure方法，保持main方法不动。<br>继承这个类的目的就是为了替代以往web.xml加载资源的方式。</p>
</li>
</ol>
<ol start="12">
<li>spring事务<br>概念：spring本身没有事务，所使用的事务本质还是数据库本身的事务.<br>声明式开启方式：<br>启动类加注解@EnableTransactionManagement<br>方法或者类加注解@Transactional，推荐方法上使用，便于细粒度控制，防止事务造成的意外情况.</li>
</ol>
<p>几个问题：<br>问题一：为啥要是用事务？<br>–为了保证一些数据库操作能同时成功和失败，因此需要放在一个数据库事务中来进行操作。</p>
<p>问题二：Spring是如何保证事务的？<br>–所谓的保证事务，目的就是让一些连续多次数据库操作在一个事务里面，因此通过共用一个数据库连接connection即可完成。<br>因此一个事务使用一个独立的connection，每个事务使用不同的connection。</p>
<p>问题三：spring中的service、dao等bean都是无状态的单例bean，单例的bean如何保证connection独立？<br>–操作数据库内部是通过一个线程来操作的，而connection是非线程安全的，同一时刻不能被多个线程共享，<br>因此每个线程需要持有独立的connection，并且互不相同、互不干扰。<br>所以我们使用事物同步管理器TransactionSynchronizationManager，实现事务的同步管理，利用ThreadLocal将数据库资源(connection)和当前事务绑定到一起，<br>使得事务传播时可以拿到正确的connection。TransactionSynchronizationManager 将 Dao、Service 类中影响线程安全的所有 “ 状态 ” 都统一抽取到该类中，<br>并用 ThreadLocal 进行封装，这样一来， Dao 和 Service就不用自己来保存一些事务状态了，从而就变成了线程安全的单例对象了。</p>
<p>参考资料：<br><a href="https://cloud.tencent.com/developer/article/1497685">https://cloud.tencent.com/developer/article/1497685</a><br><a href="https://developer.aliyun.com/article/778661">https://developer.aliyun.com/article/778661</a></p>
<ol start="13">
<li>spring mvc 流程：</li>
</ol>
<ul>
<li>http请求发送到前端控制器DispatcherServlet</li>
<li>前端控制器请求处理器映射器HandlerMapping,返回对应的处理器适配器HandlerAdapter</li>
<li>前端控制器请求适配器执行对应处理器Controller</li>
<li>controller处理器处理完后，如果是前后端一体的(@Controller)则返回ModelAndView，如果是restful风格的(@RestController)前后端分离，则返回相应的json或其他格式的字符串即可。</li>
<li>前端控制器再将返回的结果response给客户端.如果是ModelAndView对象，则还需要进行视图解析，如果是Restful风格接口，则直接返回结果。</li>
</ul>
<ol start="14">
<li>spring 核心技术 IOC AOP</li>
</ol>
<ul>
<li>IOC 控制反转，将new对象的工作交给spring 进行，spring启动时会扫描注解，根据依赖关系，自动的初始化bean，并放入对应的bean容器中，spring中好几种bean容器，因此启动时是多个容器同时进行初始化工作的；默认情况下，spring初始化出来的bean是单例的，也就是容器中只有一个bean对象，每个注入的地方都是复用同一个bean对象的。可以指定创建非单例的bean.</li>
<li>AOP 动态代理，可以实现面向切面编程，给一个bean动态的实现相应的方法。cglib,jdk方式两种不同的动态代理.   </li>
</ul>
<ol start="15">
<li>spring中的事务注解，多数据源切换都是基于AOP实现的</li>
</ol>
<ol start="16">
<li>mycat </li>
</ol>
<ul>
<li>mycat 分页查询时会改写sql，比如select * from test limit M,N,会把sql改写成select * from test limit 0,M+N,将改写后的sql分发到各个节点执行，然后再放到mycat内存里进行汇总处理。因此mycat不适合M很大的分页，必须在sql中添加有效的过滤条件尽量的减少筛选出来的数量。</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>clickhouse</title>
    <url>/2021/07/13/clickhouse/</url>
    <content><![CDATA[<h1 id="clickhouse集群搭建"><a href="#clickhouse集群搭建" class="headerlink" title="clickhouse集群搭建"></a>clickhouse集群搭建</h1><p>clickhouse是一种olap型数据库，采用列式存储，适合进行分析类业务，sql语句丰富且与mysql语句类似。</p>
<h2 id="采用的集群架构"><a href="#采用的集群架构" class="headerlink" title="采用的集群架构"></a>采用的集群架构</h2><p>vip –&gt; chproxy集群 –&gt; clickhouse集群(3*2)</p>
<span id="more"></span>
<h2 id="vip"><a href="#vip" class="headerlink" title="vip"></a>vip</h2><p>vip的一种架构方式：keepalived+haproxy，分别部署到两台机器<br>haproxy负责分发请求，keepalived负责维护haproxy节点的failover和vip的竞选。</p>
<h2 id="chproxy集群"><a href="#chproxy集群" class="headerlink" title="chproxy集群"></a>chproxy集群</h2><ul>
<li><a href="https://github.com/Vertamedia/chproxy">官网地址</a></li>
<li>chproxy集群每个节点单独部署，都是独立的节点，通过vip来负载均衡访问每个chproxy，任何一节点挂了以后不影响集群服务，只需要拉起来就行了。</li>
<li>Chproxy集群模式,是ClickHouse数据库的http代理和负载均衡器，读写请求都可以通过chproxy配置策略来访问ClickHouse集群。</li>
<li>write列表配置数据直接写入本地表,read列表配置数读取分布式表</li>
</ul>
<h2 id="clickhouse集群"><a href="#clickhouse集群" class="headerlink" title="clickhouse集群"></a>clickhouse集群</h2><h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><ul>
<li><a href="https://clickhouse.yandex/">官网地址</a></li>
<li>搭建ch集群需要zookeeper</li>
<li>ClickHouse集群模式，采用3*2模式，3个分片shard，每个shard 2个副本，两个副本互相同步数据，同时对外接收读写请求;</li>
<li>zookeeper集群用来存储ClickHouse集群的节点信息和分布式表等信息，起到协调ClickHouse集群作用;</li>
</ul>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="https://blog.csdn.net/qq_37933018/article/details/111462868">https://blog.csdn.net/qq_37933018/article/details/111462868</a></li>
<li><a href="https://www.jianshu.com/p/762f8b7d323d">https://www.jianshu.com/p/762f8b7d323d</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/103781296">https://zhuanlan.zhihu.com/p/103781296</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1488512">https://cloud.tencent.com/developer/article/1488512</a></li>
</ul>
<p>1.clickhouse私用相关文章<br>运维派clickhouse在mysql上的应用<br><a href="http://www.yunweipai.com/archives/28786.html">http://www.yunweipai.com/archives/28786.html</a><br><a href="https://www.secrss.com/articles/3173">https://www.secrss.com/articles/3173</a></p>
<p>2.解决clickhouse并发问题之CHproxy安装配置<br><a href="https://wchch.github.io/2019/06/14/%E8%A7%A3%E5%86%B3clickhouse%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98%E4%B9%8BCHproxy%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/">https://wchch.github.io/2019/06/14/%E8%A7%A3%E5%86%B3clickhouse%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98%E4%B9%8BCHproxy%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</a></p>
<p>3.分布式表建立方式<br><a href="https://www.altinity.com/blog/2017/6/5/clickhouse-data-distribution">https://www.altinity.com/blog/2017/6/5/clickhouse-data-distribution</a><br><a href="https://www.altinity.com/blog/2018/5/10/circular-replication-cluster-topology-in-clickhouse">https://www.altinity.com/blog/2018/5/10/circular-replication-cluster-topology-in-clickhouse</a></p>
<p>集群搭建参考<br><a href="http://www.clickhouse.com.cn/topic/5a366e97828d76d75ab5d5a0">http://www.clickhouse.com.cn/topic/5a366e97828d76d75ab5d5a0</a><br><a href="https://www.cnblogs.com/freeweb/p/9352947.html">https://www.cnblogs.com/freeweb/p/9352947.html</a><br><a href="https://www.jianshu.com/p/5f7809b1965e">https://www.jianshu.com/p/5f7809b1965e</a><br><a href="https://blog.csdn.net/hyesc/article/details/83022236">https://blog.csdn.net/hyesc/article/details/83022236</a><br><a href="https://www.jianshu.com/p/ae45e0aa2b52">https://www.jianshu.com/p/ae45e0aa2b52</a><br><a href="https://www.jianshu.com/p/20639fdfdc99">https://www.jianshu.com/p/20639fdfdc99</a><br><a href="https://blog.csdn.net/Alice_qixin/article/details/89209519">https://blog.csdn.net/Alice_qixin/article/details/89209519</a></p>
<h3 id="访问ch"><a href="#访问ch" class="headerlink" title="访问ch"></a>访问ch</h3><ol>
<li>官方JDBC方式直连clickhouse sever:<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">   &lt;groupId&gt;ru.yandex.clickhouse&lt;/groupId&gt;</span><br><span class="line">   &lt;artifactId&gt;clickhouse-jdbc&lt;/artifactId&gt;</span><br><span class="line">   &lt;version&gt;<span class="number">0.2</span>&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
集群模式下可以采用负载均衡方式直连，配置后端服务检查，可以自动过滤故障节点，使用方式如下：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> BalancedClickhouseDataSource <span class="title">buildBalancedClickhouseDataSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">     ClickHouseProperties properties = <span class="keyword">new</span> ClickHouseProperties();</span><br><span class="line">     <span class="comment">//直连clickhouse server</span></span><br><span class="line">     properties.setUser(<span class="string">&quot;use&quot;</span>);</span><br><span class="line">     properties.setPassword(<span class="string">&quot;pass&quot;</span>);</span><br><span class="line">     BalancedClickhouseDataSource dataSource = <span class="keyword">new</span> BalancedClickhouseDataSource    (<span class="string">&quot;jdbc:clickhouse://ip1:8123,ip2:8123,ip3:8123/databasename&quot;</span>, properties);</span><br><span class="line">     <span class="comment">//连接检查机制必须打开,否则服务端任意一个宕机后整个集群不可用</span></span><br><span class="line">     dataSource.scheduleActualization(<span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">     <span class="keyword">return</span> dataSource;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>通过http连接池方式，自定义http client客户端工具，连接chproxy集群，发送select 和 insert 请求.现有的方式是使用一个线程池，通过线程池来发送http任务。</li>
</ol>
<h3 id="集群安装"><a href="#集群安装" class="headerlink" title="集群安装"></a>集群安装</h3><ol>
<li>官网yum源下载rpm包,官网有下载方式</li>
<li>第三方打包好的安装包:<a href="https://packagecloud.io/Altinity/clickhouse">https://packagecloud.io/Altinity/clickhouse</a></li>
</ol>
<p>使用集群安装工具<br>使用clustershell安装:clush -g all -b ‘rpm -ivh /home/dpp/clickhouse-server-19.11.9.52-1.el7.x86_64.rpm’</p>
<p>安装时需要关闭swap<br>swap关闭命令:<br>1.查看swap空间和使用情况<br>swapon -s<br>free -m<br>2.关闭swap<br>swapoff /dev/dm-1<br>swapon -s<br>3.启用之前关闭分区<br>swapon /dev/dm-1<br>swapon -s</p>
<p>包名及安装顺序如下：</p>
<ul>
<li>rpm -ivh clickhouse-server-common-19.11.9.52-1.el7.x86_64.rpm</li>
<li>rpm -ivh clickhouse-common-static-19.11.9.52-1.el7.x86_64.rpm</li>
<li>rpm -ivh clickhouse-server-19.11.9.52-1.el7.x86_64.rpm</li>
<li>rpm -ivh clickhouse-debuginfo-19.11.9.52-1.el7.x86_64.rpm</li>
<li>rpm -ivh clickhouse-client-19.11.9.52-1.el7.x86_64.rpm</li>
</ul>
<p>安装前需要下载依赖包：<br>libtool-ltdl-2.4.2-21.el7_2.x86_64.rpm<br>unixODBC-2.3.1-11.el7.x86_64.rpm<br>安装异常参考：<a href="https://clickhouse.yandex/docs/en/operations/troubleshooting/">https://clickhouse.yandex/docs/en/operations/troubleshooting/</a></p>
<ol start="3">
<li>卸载及删除安装文件</li>
</ol>
<ul>
<li>yum list installed | grep clickhouse</li>
<li>yum remove -y clickhouse-common-static.xxx</li>
<li>yum remove -y clickhouse-server-common.xxx</li>
<li>rm -rf /var/lib/clickhouse</li>
<li>rm -rf /etc/clickhouse-*</li>
<li>rm -rf /var/log/clickhouse-server</li>
</ul>
<h3 id="ClickHouse-表引擎"><a href="#ClickHouse-表引擎" class="headerlink" title="ClickHouse 表引擎"></a>ClickHouse 表引擎</h3><ol>
<li>ReplacingMergeTree:  </li>
</ol>
<ul>
<li>此为MergeTree家族里具有复制功能的表引擎，需要配合zookeeper使用；采用此引擎的表，同一个shard里面的不同副本的本地表会根据zookeeper里面的表节点信息，互相增量同步彼此没有的分区数据。</li>
<li>insert数据时，会随机挑选某个shard里面的某一个副本节点进行插入操作，其他副本后台进行同步数据，达到不同副本之间的数据一致性和可靠性。</li>
<li>select数据通过distributed table 读取数据，http请求被分配到某一个分布式表的节点上，此节点再将sql分发到其他分片，并行执行sql语句，然后将数据汇聚到初始http请求节点，返回给用户。图片解析可以百度: clickhouse reading from distributed table</li>
</ul>
<h3 id="建表语句"><a href="#建表语句" class="headerlink" title="建表语句"></a>建表语句</h3><p>建表需要创建两种表:本地表和分布式表<br>本地表示例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> dbname.tablename <span class="keyword">ON</span> CLUSTER `cluster<span class="operator">-</span>name`</span><br><span class="line">(</span><br><span class="line">`db_id` Int32, </span><br><span class="line">`status_name` String, </span><br><span class="line">`status_value` String, </span><br><span class="line">`time_stamp` DateTime <span class="keyword">DEFAULT</span> now()</span><br><span class="line">)ENGINE <span class="operator">=</span> ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/clustername/dbname/tablename/&#123;shard&#125;&#x27;</span>, <span class="string">&#x27;&#123;replica&#125;&#x27;</span>)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMMDD(time_stamp)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (db_id, time_stamp, status_name);</span><br></pre></td></tr></table></figure>
<p>‘/clickhouse/clustername/dbname/tablename/{shard}’: The path to the table in ZooKeeper.<br>‘{replica}’：The replica name in ZooKeeper.<br>两个变量的值均从配置文件中自动读取替换。</p>
<p>分布式表：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> dbname.tablename_all <span class="keyword">ON</span> CLUSTER `clustername` <span class="keyword">AS</span> dbname.tablename</span><br><span class="line">ENGINE <span class="operator">=</span> Distributed(<span class="string">&#x27;clustername&#x27;</span>, <span class="string">&#x27;dbname&#x27;</span>, <span class="string">&#x27;local_tablename&#x27;</span>, rand());</span><br></pre></td></tr></table></figure>
<p>note: MergeTree家族引擎必须要有一个 Date 的列来作为索引。</p>
<h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ol>
<li>表的建法</li>
</ol>
<ul>
<li>本地表和分布式表都采用集群模式sql语句建立，不要在每台机器上一个一个建，防止元数据同步不一致</li>
</ul>
<ol start="2">
<li>sql写法的小建议</li>
</ol>
<ul>
<li>join时大表在左小表在右,JOIN操作时一定要把数据量小的表放在右边，ClickHouse中无论是Left Join 、Right Join还是Inner Join永远都是拿着右表中的每一条记录到左表中查找该记录是否存在，所以右表必须是小表。</li>
<li>多表关联时，需在子查询里增加过滤条件，尽量提前缩小数据范围。</li>
<li>如果不想加where条件，那么可以提前构建大宽表或者预计算</li>
<li>clickhouse的in用法比join效率高；多个列可以组合成一个tuple类型使用，可以结合in使用</li>
<li>筛选分区select … from xxx where partition_expr=xxx</li>
</ul>
<ol start="3">
<li>副本的failover方式</li>
</ol>
<ul>
<li>一个shard里面的不同副本是可以同时对外服务的，正常情况下每个副本可以根据配置，接收insert和select 类sql，如果某个副本不可用，chproxy会自动重发到其他可用副本。</li>
</ul>
<ol start="4">
<li>clickhouse索引模式</li>
</ol>
<ul>
<li>clickhouse采用稀疏索引，默认粒度8192，每隔固定长度会在索引相关文件里设置索引信息，涉及数据文件cloum_name.bin和标记文件cloum_name.mrk2，clickhouse中的数据是每个列一个文件，内部采用压缩模式存储。适合检索大数据量下的数据集，server会根据sql中的索引字段自动检索到适合的范围内数据块，然后会读取索引区间之间的所有数据。稀疏索引会引起额外的数据读取，当读取主键单个区间范围的数据时，每个数据块中最多会多读 index_granularity * 2 行额外的数据。大部分情况下，当 index_granularity = 8192 时，ClickHouse的性能并不会降级。</li>
</ul>
<ol start="5">
<li>集群方式删除表分区</li>
</ol>
<ul>
<li>ALTER TABLE table_name ON CLUSTER ‘cluster_name’ DROP PARTITION partition_expr<br>举例：alter table mon_database_status on cluster ‘cluster-1’ drop partition 20191104<br>其中，partition_expr表达式不可用单引号/双引号修饰，否则会报异常 : DB::Exception: There was an error on [snk207:9000]: Cannot execute replicated DDL query on leader.<br>这个方式可以只需要在某个server节点上执行一次就可以删除集群中所有的此表的词分区，不用每个分片一个一个执行。</li>
</ul>
<ol start="6">
<li>clickhouse的复制表中的leader说明</li>
</ol>
<ul>
<li>Leader replica just coordinates some background processes, leveraging ZooKeeper cluster. So unlike master/slave setup in other DBMS, in ClickHouse you shouldn’t care about replica leadership status for reads and writes.<br>More details are over here: <a href="https://clickhouse.yandex/docs/en/operations/table_engines/replication/">https://clickhouse.yandex/docs/en/operations/table_engines/replication/</a></li>
</ul>
<ol start="7">
<li><p>zookeeper对replicate table的影响<br>如果clickhouse服务启动正常，此时zookeeper不可用，那么clickhouse中的replicate table会变成read_only模式；<br>同时，在insert的过程中，如果zookeeper不可用，或者clickhouse与zookeeper交互有异常，都会抛出异常，执行失败；</p>
</li>
<li><p>修改不同分片的权重比例</p>
</li>
</ol>
<ul>
<li>场景1：通过chproxy来插入数据，则在配置文件中，为负载均衡的服务节点设定不同分片的比例，比如将&lt;204,205&gt;设置为1/3,&lt;206,207&gt;设置为2/3，如下所示，实测生效;<br>nodes:<br>[<br>“snk204:8123”,<br>“snk205:8123”,<br>“snk206:8123”,<br>“snk207:8123”,<br>“snk206:8123”,<br>“snk207:8123”<br>]</li>
</ul>
<p>目前测试，修改完配置文件后重启生效.<br>chproxy可以修改配置文件后动态加载，不用重启服务，方法为：ps -ef|grep -v grep |grep -v nohup|grep chproxy|awk ‘{print $2}’|xargs kill -HUP，此为想进程发送SIGHUP信号,让进程重新加载服务。</p>
<ul>
<li>场景2：clickhouse的配置文件中的分片权重<br>通过在<shard>标签里面的属性设置<weight>1</weight>，这种情况是通过分布式表插入数据时，分配的比重。</li>
</ul>
<ol start="9">
<li><p>clickhoues的TTL功能bug<br>目前使用的版本为:ClickHouse version 19.11.9.52. 对此版本的表级别TTL进行试验测试，TTL无效，官方证实为bug，说是在11.14版本修复。</p>
</li>
<li><p>物化视图(materialized view)<br>物化视图的作用：</p>
</li>
<li><p>时序层面物化：从一个表衍生划分出不同的时间维度表的表</p>
</li>
<li><p>维度层面物化：针对不同的维度衍生出不同维度的不同engine表<br>物化视图的建法：</p>
</li>
<li><p>分片多副本模式下，用on cluster集群方式建立replicated*模式表，在每个节点上创建一个本地物化视图，再在集群上创建一个分布式表来查集群的物化视图;</p>
</li>
<li><p>其他模式下自选</p>
</li>
<li><p>truncate 删除表数据默认禁止超过50G的数据，需要按提示进行操作，创建一个force文件后，就可以删除了。</p>
</li>
<li><p>order by是对表中的数据进行排序存放,主键可以和排序排序键不一样,但是必须是排序键的前缀,也就是order by的前面几个字段</p>
</li>
</ol>
<h3 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h3><ol>
<li><p>新增分片<br>即给集群新增若干分片，比如从2个分片，增加到3个分片  </p>
<blockquote>
<p>处理步骤：</p>
<blockquote>
<p>1.准备好新增分片的机器<br>2.在新增机器上安装好clickhouse各个元件，修改一份最新全集群的配置文件，然后同步到集群所有节点，根据分片号，修改相应标签值。clickhouse的配置文件是动态生效的。此时，已经可以查询到新增分片了<br>3.启动新分片的机器，此时zookeeper中没有新分片信息，然后在新节点上创建一份与其他节点一致的库和表（此时的建库建表应该在每个节点使用本地模式执行，不能加 on cluster语句，{shard},{replicate}的占位符依旧可以使用），此时zookeeper已经存在新分片的表信息了，并且新节点可以查询分布式表中的数据和执行集群相关操作<br>4.此时的新分片还未对外服务，不能接受插入数据请求。因此在chproxy中添加节点信息，重启chproxy服务，新分片即可对外服务，同时给新增分片增加数据权重，达到数据均衡。等到数据大致平衡后再修改一次分片权重。<br>方案实测生效。</p>
</blockquote>
</blockquote>
</li>
<li><p>新增副本</p>
<blockquote>
<blockquote>
<p>1.副本的Clickhouse安装同上<br>2.更改新的添加副本的配置文件，同步到所有节点<br>3.启动新的副本节点，创建库和表，此时新的副本就会自动同步数据了，并且未在chproxy中登记，暂时可以不对外服务<br>4.将新的副本增加到chproxy的均衡节点中，就可以正常使用了。<br>方案实测生效。<br>副本的减少操作类似</p>
</blockquote>
</blockquote>
</li>
</ol>
<h3 id="集群维护"><a href="#集群维护" class="headerlink" title="集群维护"></a>集群维护</h3><ol>
<li>chproxy集群中某台服务宕机，则直接拉起服务继续使用</li>
<li>一个shard中的某个副本节点宕机，则</li>
</ol>
<ul>
<li>重新拉起CK服务，如果启动正常，则会自动同步丢失的数据</li>
<li>若副本节点所在机器损坏不可用，则直接更换部分机器，并更新节点中的配置文件，用新的副本替换原来的副本，新增副本的方法见《新增副本》,zookeeper中会自动删除下线副本节点。</li>
</ul>
<ol start="3">
<li>扩容分片方法，见《新增分片》方法;剔除分片zookeeper是不会自动删除节点的。</li>
</ol>
<h3 id="数据搬迁"><a href="#数据搬迁" class="headerlink" title="数据搬迁"></a>数据搬迁</h3><p>当遇到数据需要从一个集群迁移到另一个集群时，有如下方法：</p>
<ol>
<li><p>方法一：<br>通过remote表函数来实现，这种方式主要是用来每次执行一个表的数据迁移,表的数据量不是太大，语句格式为：<br>insert into db.table select * from remote(‘addresses_expr’, db.table[, ‘user’[, ‘password’]]);<br>在需要导入数据的新集群执行。</p>
</li>
<li><p>方法二：<br>通过clickhouse-copier工具来迁移，这种方式可以处理任意大小的集群数据，可以通过配置文件来同时以此同步不同的表数据，需要与zookeeper结合使用；</p>
</li>
</ol>
<p>命令为：<br>clickhouse-copier copier –config /etc/clickhouse-sever/zookeeper.xml –task-path /clickhouse/copytasks/task1 –task-file schema.xml  –base-dir /data/clickhouse-copier –task-upload-force true </p>
<p>(官方–daemon方式运行不起作用，有待考究)<br>或者自己实现后台执行模式:<br>clickhouse-copier copier –config /etc/clickhouse-sever/zookeeper.xml –task-path /clickhouse/copytasks/task1 –task-file /etc/clickhouse-sever/schema.xml  –base-dir /data/clickhouse-copier –task-upload-force true &gt;/dev/null 2&gt;&amp;1 &amp;<br>其中：–config,–task-path,–base-dir涉及到的文件或者目录可以自定义位置</p>
<p>参数含义：<br>Parameters:<br>daemon — Starts clickhouse-copier in daemon mode.<br>config — The path to the zookeeper.xml file with the parameters for the connection to ZooKeeper.<br>task-path — The path to the ZooKeeper node. This node is used for syncing clickhouse-copier processes and storing tasks. Tasks are stored in $task-path/description.<br>task-file — Optional path to file with task configuration for initial upload to ZooKeeper.<br>task-upload-force — Force upload task-file even if node already exists.<br>base-dir — The path to logs and auxiliary files. When it starts, clickhouse-copier creates clickhouse-copier_YYYYMMHHSS_<PID> subdirectories in $base-dir. If this parameter is omitted, the directories are created in the directory where clickhouse-copier was launched.</p>
<p>命令会把task-file指定的文件上传到zookeeper节点路劲task-file下，无需人工上传任务文件.<br>实验测试使用步骤如下：<br>1.准备zookeeper.xml配置文件</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">yandex</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">logger</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">level</span>&gt;</span>trace<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">size</span>&gt;</span>100M<span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">count</span>&gt;</span>3<span class="tag">&lt;/<span class="name">count</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">zookeeper</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">node</span> <span class="attr">index</span>=<span class="string">&quot;1&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">host</span>&gt;</span>snk204<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">port</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">node</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">zookeeper</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">yandex</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>2.准备任务描述文件schema.xml，里面把数据的流转方式填写完善<br>3..执行迁移数据命令<br>clickhouse-copier copier –config /etc/clickhouse-sever/zookeeper.xml –task-path /clickhouse/copytasks/task1 –task-file /etc/clickhouse-sever/schema.xml  –base-dir /data/clickhouse-copier –task-upload-force true &gt;/dev/null 2&gt;&amp;1 &amp;<br>或者<br>clickhouse-copier copier –config /etc/clickhouse-sever/zookeeper.xml –task-path /clickhouse/copytasks/task1 –task-file /etc/clickhouse-sever/schema.xml  –base-dir /data/clickhouse-copier –task-upload-force true<br>4.查看任务同步状态<br>在/data/clickhouse-copier目录下会创建一个当前任务的子目录，可以通过查看下面的日志来了解任务同步状态.<br>等待数据同步完成即可。<br>NOTE:<br>clickhouse-copier每个同步完的分区会写在zookeeper的节点中，当重复执行命令时，并不会对已经完成的分区数据重复执行。并且clickhouse-copier一旦读取完数据就会停止任务进程。<br>因此这种方式适合于同步那些分区数据不会再变化的数据。</p>
<ol start="3">
<li>方法三：<br>通过修改clickhouse的集群配置文件，给每个分片增加新副本但是新副本可以不对外服务的方式，将老副本的数据同步到新副本，待数据同步差不多时，剔除旧的副本和机器，再次修改集群配置文件，将上游任务重定向到新的集群中即可。</li>
</ol>
<h3 id="clickhosue-中一些常用命令"><a href="#clickhosue-中一些常用命令" class="headerlink" title="clickhosue 中一些常用命令"></a>clickhosue 中一些常用命令</h3><ol>
<li>clickhouse-client -u default -h 127.0.0.1 -m</li>
<li>clickhouse-client -u default -h 127.0.0.1 -m -q “xxx_sql”</li>
<li>systemctl stop clickhouse-server.service</li>
<li>systemctl restart clickhouse-server.service</li>
<li>systemctl status clickhouse-server.service</li>
<li>sudo service clickhouse-server status</li>
<li>alter table db.table drop partition 20210408</li>
</ol>
<h3 id="额外补充"><a href="#额外补充" class="headerlink" title="额外补充"></a>额外补充</h3><ol>
<li>mysql语法中的执行顺序:<br>SELECT语句的完整语法为：<br>(7) SELECT<br>(8) DISTINCT <select_list><br>(1) FROM <left_table><br>(3) <join_type> JOIN <right_table><br>(2) ON <join_condition><br>(4) WHERE <where_condition><br>(5) GROUP BY <group_by_list><br>(6) HAVING <having_condition><br>(9) ORDER BY <order_by_condition><br>(10) LIMIT <limit_number></li>
</ol>
<p>案例:<br> SELECT a.customer_id, COUNT(b.order_id) as total_orders<br> FROM table1 AS a<br> LEFT JOIN table2 AS b<br> ON a.customer_id = b.customer_id<br> WHERE a.city = ‘hangzhou’<br> GROUP BY a.customer_id<br> HAVING count(b.order_id) &lt; 2<br> ORDER BY total_orders DESC;</p>
<ol start="2">
<li><p>group by语句的写法需要注意最后结果的唯一性,不能使select里面的字段产生某个列有多个值,并且select里面的字段要么在group by里面,要么用聚合函数来计算<br>clickhouse中的语法:<br>!!!clickhouse语法中写明order by顺序在select之前,和mysql中的顺序不一样.<br>如果存在GROUP BY子句，则在该子句中必须包含一个表达式列表。其中每个表达式将会被称之为“key”.<br>SELECT，HAVING，ORDER BY子句中的表达式列表必须来自于这些“key”或聚合函数。<br>简而言之，被选择的列中不能包含非聚合函数或key之外的其他列。<br>与MySQL不同的是（实际上这是符合SQL标准的），你不能够获得一个不在key中的非聚合函数列（除了常量表达式）。<br>但是你可以使用‘any’（返回遇到的第一个值）、max、min等聚合函数使它工作。</p>
</li>
<li><p>当通过proxy写ck时,proxy到CK服务端大量的tcp_tw来源于分片中副本之间的复制造成<br>当前端写proxy的过程中,如果http端为短连接,那么就会在proxy端产生大量的tcp_tw,如果为长链接,那么在proxy端会复用tcp连接.<br>但是http端的请求不会影响CK服务端,只有chproxy端才会影响CK.</p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>mysql相关</title>
    <url>/2021/07/02/mysql%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<ol>
<li>select * for udpate</li>
</ol>
<ul>
<li>for udpate应用的是悲观锁，根据select的数据集范围会对不同量级的数据进行加锁，<br>良好情况下，比如通过主键、索引定位到行，则进行行加锁，<br>较差情况下，可能进行表锁，使用时需要针对不同的sql进行分析，判定加锁的范围。<br>在高并发下，可能对性能有影响。</li>
</ul>
<span id="more"></span>
<ol start="2">
<li>笛卡尔积</li>
</ol>
<ul>
<li>mysql中的inner join,left join,right join都会涉及到笛卡尔积相关概念，真实作用后的结果一般为局部笛卡尔积。<br>当多个表进行连接时，推荐使用on进行连接，这样可以避免两张表进行全量的笛卡尔积(两张表每个都会进行匹配一行结果)，<br>on作用会先根据on的条件关联出符合的两行再组成一个完整的行数据，如果使用where进行关联，则两个表会先进行全量的笛卡尔积，<br>然后再根据where条件把符合条件的数据筛选出来。当两张表的数据很大时，on和where的效率会很明显。</li>
</ul>
<ol start="3">
<li>select 语句执行过程</li>
</ol>
<ul>
<li>首先通过连接器进行会话连接(加入session还没有创建,如果创建了就没有这一步)，然后进入分析器进行语法分析，然后进入优化器进行语法优化，最后进入执行器进行sql执行,如何内存中有缓存可能直接在内存中就能找到数据，如果禁用了缓存，则每次从磁盘中查找数据到内存，再返回给客户端.</li>
</ul>
<ol start="4">
<li>update 语句执行过程</li>
</ol>
<ul>
<li>连接器-&gt;分析器-&gt;优化器-&gt;执行器,和select不同的是执行器里面逻辑不同，首先从内存中查找数据(此数据所在的数据页在内存中)，如果有直接取出对应的行数据进行更新，如果没有,并且走的是主键索引，则从磁盘捞出对应的数据放入内存，然后做相应的更新操作，更新完刷新内存中的值，同时写入redo log，然后再写入binglog，提交事务，代表此次更新完成。这就能保证数据库从crash状态恢复时，不会丢数据，简称crash-safe。如果内存中没有整个数据，并且更新走的是二级索引(普通索引)，那么就会将变更放在change buffer中，同时在redo log中记录change buffer类型的日志信息，再写入binglog，提交事务。当下次有个select语句要查询刚才和放入change buffer一样记录时，就会从磁盘捞取相应的数据页到内存中，再作用change buffer中的变更，最后将更新后的数据方会给客户端，同时内存里保存最新的数据。只有走普通索引时才会使用change buffer，主键时不会使用，change buffer可以减少随机读磁盘次数，redo log可以减少随机写磁盘次数，这两个都有相应的物理日志(有相应的文件名对应)，mysql后台会有个merge线程定时的将内存中的脏页数据刷到磁盘，并不是将redo log和change buffer的日志信息输入磁盘，这两个日志是在宕机恢复时才会使用的。</li>
<li>写redo log文件，是在更新内存之后的.</li>
<li>redo log记录的不是具体的数据是数据页的变化，磁盘上面的数据也不是根据redo log来修改的，是把内存中的数据页的脏页刷新到磁盘数据页中</li>
<li>redo log的文件在mysql里面通常有几个，命名格式为ib_logfile0,ib_logfile1…,个数和大小可以设置。redo log技术就是mysql中的WAL技术(write-Ahead logging),就是先写日志，在写磁盘。redo log日志放在redo log file后会在恰当的时机将数据刷到数据文件即表中。</li>
<li>redo log 和binglog的刷盘策略可以设置，分别设置innodb_flush_log_at_trx_commit和sync_binlog两个都为1时就能提供两阶段提交功能，保证数据不丢失，即使mysql异常宕机重启。redo log是innodb引擎的log文件，binglog是mysql server自带的log文件。</li>
<li>何时会擦除redo log并更新到数据文件中：系统空闲时、redo log file空间不足时、mysql正常关闭时。</li>
<li>形象化的来理解数据更新操作：我们假设操作数据库相当于饭店掌柜经营生意。因为mysql的架构是mysql server 和存储引擎是分开的，所以我们假设server就是掌柜，redo log相当于临时记账的黑板，账本相当于表数据文件。通常有人来赊账或者还款时就会先将这个信息记录在黑板，等黑板记录满了或者掌柜空闲了，就会来将黑板的信息记录到账本。</li>
</ul>
<ol start="5">
<li>事务隔离级别</li>
</ol>
<ul>
<li>mysql中的数据读完之后是放在内存中的缓存页里的，缓存页里的是一行行的数据。</li>
<li>mysql中的事务隔离级别分类: 读提交(read_committed)、可重复读(repeatable_read)、读未提交(read_uncommitted)、串行化(serializable),每种隔级别都有其各自的应用场景，不过我们重点关注读提交和可重复读</li>
<li>读提交: 只能读到已经committed的数据。在一个事务中，每次执行sql时会重新创建一个一致性读视图(read view)，然后读视图里的数据，因此可以存在前后读取的数据不一样，因为数据可能被其他事务修改并提交了</li>
<li>可重复读：只能读到已经committed的数据，并且读取数据的视图是在事务开始时创建的，其他事务提交的数据在此次事务中不可见，因此在事务中读取的数据每次都是一样的。</li>
<li>事务隔离级别是用来解决并发读写冲突时一系列问题的手段(附属mvcc)，问题包括：脏写，脏读，幻读，不可重复读，具体来说不同的事务隔离级别对应的快照读结果不一样，不同的隔离级别解决的问题也不一样。<ul>
<li>脏写:事务A与事务B写同一行数据，因为事务A的回滚，导致事务B的更新失效。某一行数据初始值V0,事务A修改成V1，事务B修改成V2,因为事务A回滚，导致数据变成了V0，而事务B的更新也被抹掉了。</li>
<li>脏读：事务B因为事务A回滚，导致前后读取的数据不一致；某行数据开始是为v0,事务A修改后为V1，事务B第一次读取为V2，后来事务A回滚，事务B第二次读到V0，而不是V1.</li>
<li>幻读：事务A因为事务B，导致事务A第二次比第一次多读取都数据。事务A的sql一开始可以读到10条数据，当事务B的sql执行完之后，事务A再执行一遍相同sql，冒出15条是数据，那么事务A前后两次读取的结果不一样，认为是出现了幻觉。</li>
<li>不可重复读：事务A因为事务B的提交，导致前后读取的值不一致。事务A的sql第一次读取某条数据为v1,事务B修改为v2并提交，事务A再读时为V2，而不是v1.</li>
<li>参考：<a href="https://blog.csdn.net/weixin_39616674/article/details/110868947">https://blog.csdn.net/weixin_39616674/article/details/110868947</a></li>
<li>那么，不同的隔离级别会导致什么问题呢？待补充</li>
<li>读提交是会存在幻读的。</li>
</ul>
</li>
<li>mvcc原理理解:<a href="https://blog.csdn.net/SnailMann/article/details/94724197%EF%BC%8Cmvcc%E7%9A%84%E5%AE%9E%E7%8E%B0%E9%9C%80%E8%A6%81%E7%BB%93%E5%90%88">https://blog.csdn.net/SnailMann/article/details/94724197，mvcc的实现需要结合</a> 记录的3个隐式字段、undo log、read view(附属隔离级别的一致性读视图)一起来实现。</li>
<li>innodb里面的读分为:当前读和读快照。当前读指读取最新数据，并且会对数据进行加锁，不准其他事务修改数据；快照读指的是不加锁的读，基于mvcc实现，读到的数据可能不是最新版本。</li>
<li>mysql中的并发场景分为：读-读，读-写，写-写，mvcc只能解决读-写的并发问题，可以提高mysql的并发能力，可以解决读时不阻塞写，写时不阻塞读，以及脏读，幻读，不可重复读问题，但是不能解决数据更新丢失问题。写-写引发的问题需要引入锁来解决。</li>
<li>事务的隔离级别在代码上就是通过MVCC实现的。</li>
</ul>
<ol start="6">
<li>innodb引擎采用B+树存储数据</li>
</ol>
<ul>
<li>innodb是按索引顺序进行存储数据的，插入数据后必须保证索引数据是有顺序的。存储数据的方式有很多重，比如hash表，有序数组，二叉树等，其中hash表只能进行等值查找，根据k值找到对应的位置数据，查询的方式受限；数组存储方便按位置索引查询数据，但是插入数据后需要移动数据，因此也不能使用；二叉树的查询效率相对较高，小于根节点的放左边，大于的放右边，比如一个二叉树放100次数据，大约需要20层就可以存下，也就是从磁盘查询一次数据大约需要20次，每次磁盘读数据块大约10ms。不过因为二叉树为了保证效率，有序，插入数据后还需要保证是平衡二叉树，因此也会进行搬迁数据，所以综上，当一个节点下面有N(&gt;2)个节点时，就可以在一层存放更多的数据，也就形成了N叉树，这就是B+数据的精髓。假如一个表的主键索引是一个整型值，那么一个数据页大约可以存1200多个节点，也就是N=1200，那么铺满4层节点的数据，也就是1200的3次方值，大约17亿。所以查找一个10亿数据量的表的索引，大约访问3次磁盘就能找到对应的数据页了，查询效率很高。所以N叉树在读写的性能比较突出，又适配磁盘的随机读取方式(给一个索引位置，就可以直接去索引对应的磁盘位置查找数据页)，可以减少单次查询访问磁盘的次数，因此被很多存储索引采用。</li>
<li>innodb引擎里的表实际就是多个B+数据，数据存放在主键索引的B+树节点上，其他的索引(二级索引)B+树节点下面存放的主键索引值。</li>
<li>B+树的叶子节点存储的时page，一个page可以存储多行。N是由页大小和索引大小决定的。</li>
<li>一个数据页大小是16k， 如果有的数据超过16k，就会放在多个不同的数据页上，查这样的记录是要访问多个数据页的</li>
</ul>
<ol start="7">
<li>走索引的特殊案例</li>
</ol>
<ul>
<li>最左前缀原则，B+树的索引结构，可以利用索引的最左前缀原则来定位记录，这个最左前缀可以是联合索引的最左N个字段，可以是字符串索引的最左M个索引，所以like语句中like “xxx%”可以走索引，但是like “%xxx”不能走索引(like 更详细的使用规则待修订)</li>
<li>name like “%xx”/“%x%”语句是否走索引问题研究:<ul>
<li>%在最左边时，一般不走索引树快速定位，因为不满足最左原则，而是直接遍历整个主键索引树或者二级索引树；</li>
<li>那什么时候走主键索引树，什么时候走二级索引树？<ul>
<li>当name是联合索引中的一部分，并且select里面也有联合索引字段，那么走二级索引，因为二级索引的叶子节点的数据少，索引树的内存占用少，走主键就会遍历整理表，内存占用大</li>
<li>当name是普通索引时，并且select的字段不是索引字段，就会走遍历主键索引树(全表查询)，避免回表。</li>
<li>注意两点:通过索引树快速定位和通过索引树遍历查询是两个东西，第一个表示走索引进行快速定位，第二个只是表示会选择一个索引树进行全部遍历，然后进行条件匹配选择，比如遍历主键索引树表示全表扫描，遍历二级索引树表示扫描整个二级索引树的所有节点，然后跳到合适的数据节点再根据情况进行回表到主键索引树进行查询其他字段结果。</li>
</ul>
</li>
</ul>
</li>
<li>name between a and b,若name符合索引的最左原则，则可以走索引查询，而且效果比name in (xx,xx,xx)好，因为in</li>
<li>索引分为一级索引(主键)和二级索引(普通索引)，优先推荐直接走主键索引，当必须走二级索引时，会发生一个回标操作或者索引下推操作(5.6开始)，二级索引节点下面存放的数据时主键索引值，当二级索引下面的节点包含了一些where条件时，会优先通过索引下推的方式来进行过滤数据或者直接给出数据，比如select id from test where name like ‘张%’ and age =10 and gender=’男’;<br>如果主键索引为id,二级索引为(name,age)时，就会在使用name的同时，在判断age是否符合，最后再到主键索引里面根据gender捞取符合的数据。</li>
<li>删除索引或者创建主键都会导致整个表重建</li>
</ul>
<ol start="8">
<li>MyISAM引擎</li>
</ol>
<ul>
<li>不支持事务</li>
<li>不支持行锁，支持表锁</li>
</ul>
<ol start="9">
<li>mysql中锁的种类</li>
</ol>
<ul>
<li>全局锁，锁整个数据库</li>
<li>表级锁，锁整个表</li>
<li>行级锁，锁一个或者多行数据</li>
<li>读锁S，是共享锁</li>
<li>写锁X，是排他锁</li>
<li>间隙锁,只在可重复读隔离级别下才会有，当定位不到一个行时，会将行与行之间的间隙给加锁，导致落入这个间隙的数据也不能插入</li>
</ul>
<ol start="10">
<li><p>数据库中的乐观锁</p>
<ul>
<li>就是指MVCC</li>
</ul>
</li>
<li><p>数据库并发优化</p>
</li>
</ol>
<ul>
<li>缩小事务长度，将多个事务变更的相同行记录放在最后操作，减少事务占用的时间</li>
<li>打开死锁自动检测，同时通过降低访问相同资源的并发量降低死锁的概率</li>
</ul>
<ol start="12">
<li>死锁检测时机</li>
</ol>
<ul>
<li>当一个事务要加锁访问的行上已经有锁时，才会去检测是否死锁，并且也不是检测所有的事务，而是只检测有关联性的事务之间是否存在死锁。</li>
<li>对于普通的读是不需要检测死锁的，因为读的是在事务隔离级别下的快照都，非当前读。</li>
</ul>
<ol start="13">
<li>事务启动时机</li>
</ol>
<ul>
<li>begin/start transaction 并不是一个事务的起点，当在真正开始执行一个操作innodb表语句的sql时，事务才真正启动。</li>
</ul>
<ol start="14">
<li>MVCC相关</li>
</ol>
<ul>
<li>mvcc解决的是读写冲突，里面涉及到的一致性读视图read view是读快照，重点是规定读的数据范围，当事务里同时用到更新语句时，使用的是当前读，也就是必须读最新的提交数据，因为有个原则是，更新数据之前必须先读再写，而这个读就是“当前读”</li>
<li>InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。<ul>
<li>对于可重复读，查询只承认在事务启动前就已经提交完成的数据(时间维度来理解);</li>
<li>对于读提交，查询只承认在语句启动前就已经提交完成的数据(时间维度来理解)；</li>
</ul>
</li>
</ul>
<ol start="15">
<li>sql语句优化</li>
</ol>
<ul>
<li>使用强制索引force index，优点是可以人为指定走哪个索引，防止mysql基于行数等统计值选错索引，缺点是sql语句不优雅，而且如果索引名字变化或者索引被删除，就会导致语句出问题，而且迁移到别的数据库也可能语法不兼容.</li>
</ul>
<ol start="16">
<li>如果某次写入使用了 change buffer 机制，之后主机异常重启，是否会丢失 change buffer和数据?</li>
</ol>
<ul>
<li>这个问题的答案是不会丢失，虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。</li>
</ul>
<ol start="17">
<li>merge：应用change buffer中与该数据页相关的操作的这个过程，我们称之为数据页的merge操作<br>第一步:merge 的执行流程是这样的：从磁盘读入数据页到内存（老版本的数据页）；<br>第二步:从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；<br>第三步:写 redo log。这个 redo log 包含了数据页的变更(Merge的过程中要修改数据页)和 change buffer 的变更。<br>到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。<br>参考链接:<a href="https://cloud.tencent.com/developer/article/1624144">https://cloud.tencent.com/developer/article/1624144</a><br>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。</li>
</ol>
<ol start="18">
<li>explain 各个字段解析</li>
<li>如何将较长的字符串作为索引:</li>
</ol>
<ul>
<li>mysql支持前缀索引，可以将字符串的一部分作为索引。这里字符串的长度要选择尽量有区分度，减少查询的次数。</li>
<li>将字符串计算成成hash值存储</li>
</ul>
<ol start="20">
<li>mysql什么时候flush脏页</li>
</ol>
<ul>
<li>redo log满了，这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。checkpoint 可不是随便往前修改一下位置就可以的。把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志，对应的所有脏页都 flush 到磁盘上。之后，从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。</li>
<li>系统内存满了，就要淘汰内存中的一些数据页，如果淘汰的是”脏页”，就要将脏页写到磁盘.</li>
<li>MySQL 认为系统“空闲”的时候.?啥叫空闲,io低？</li>
<li>mysql正常关闭的时候.<br>备注:刷脏页过程不用动redo log文件的,redo log在“重放”的时候，如果一个数据页已经是刷过的，会识别出来并跳过。</li>
</ul>
<ol start="21">
<li><p>mysql断电重启<br>如果断电了重启导致内存丢失，通过redo log进行数据恢复,Redolog 的空间是循环使用的，无所谓释放。 对应的内存页会变成干净页。但是等淘汰的时候才会逐出内存.<br>重启了就从checkpoint 的位置往后扫。 如果已经之前刷过盘的, 不会重复应用redo log.</p>
</li>
<li><p>几种概念<br>flush 一般是说刷脏页，<br>purge一般是指清undo log,<br>merge一般是指应用change buffer</p>
</li>
<li><p>分页</p>
</li>
</ol>
<ul>
<li>对于存在limit 10000000,10类似这中的分页，比如有主键id表示，可以搜索下一页的时候带上上一页最大的id条件进行搜索如where id &gt; last_max_id limit 10;或者先把所有的id挑选出来，再根据id进行回表查其他字段数据,select * from t where id in (select id from t where xxx);</li>
</ul>
<ol start="24">
<li>order by 执行流程</li>
</ol>
<ul>
<li>先根据sql语句将数据捞到内存，然后根据sort buffer大小，如果小于设定值，则直接在内存里排序，如果大于，则在磁盘中使用临时文件进行局部排序，再根据归并排序进行全局合并，最后返回给客户端.</li>
</ul>
<ol start="25">
<li>为啥对索引使用函数就会导致用不上索引了？</li>
</ol>
<ul>
<li>真是原因是，当对索引使用函数后，就会破坏索引的有序性，因此优化器就会放弃走树搜索功能，导致会进行全索引扫描，可能会选择主键索引，也可能选择其他普通索引，失去了索引的快速定位功能,并不是说不会走索引了。</li>
</ul>
<ol start="26">
<li>索引字段的类型隐式转换也会导致快速定位功能失效，进而全索引扫描</li>
</ol>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
</search>
